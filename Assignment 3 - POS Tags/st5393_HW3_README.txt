verview
--------
The tagger is built around two complementary pipelines:
1. **Trigram HMM + enhanced Viterbi** – our primary system, tuned with extensive OOV heuristics.
2. **Averaged Perceptron sequence tagger** – a discriminative baseline with rich lexical/contextual features.

Even in the "train+dev" high-accuracy mode we still rely on the same training/decoding logic in `st5393_HMM.py` and `st5393_Viterbi.py` (the only change is that the training corpus is expanded to include the development set). These two modules therefore remain the primary pipeline. The perceptron implementation offers a reproducible, easily extensible discriminative alternative.

Training (`st5393_HMM.py`)
-------------------------
* Reads one or more tagged corpora and collects:
  * trigram and bigram tag transition counts; 
  * tag-conditioned emission counts; 
  * hapax counts for unknown-word modelling.
* Converts raw counts into probabilities with add-ε smoothing (ε = 1e‑3).
* Builds a log-space decoder package containing:
  * interpolated transition logs (λ = 0.7/0.2/0.1 for trigram/bigram/unigram);
  * log emission tables and several cached lexicons (NN vs JJ bias, NNPS preference, dominant tags, etc.);
  * hapax-based OOV distributions keyed by surface features (suffixes, capitalisation, digits, hyphenation).

Decoding (`st5393_Viterbi.py`)
-----------------------------
* Runs a trigram Viterbi search in log space. Candidate tags per word default to those seen in training (falling back to all tags when necessary). Unknown words use the cached OOV distributions instead of uniform smoothing.
* Applies contextual bias terms before scoring to favour plausible tag choices for troublesome patterns: 
  * preposition/adverb ambiguities such as “down/up/out/about/ago”; 
  * numeric contexts (“108.1 million shares” → `CD`/`NNS`); 
  * capitalised words following determiners when they almost always act as nouns.
* After dynamic programming, runs `_refine_tags` to clean persistent confusions:
  * VBD/VBN swaps based on neighbouring nouns, auxiliaries, and date patterns; 
  * NN/JJ vs NN/NNP distinctions using training dominance, determiner context, and curated lexicons (e.g., “net income”, “Big Board”);
  * NNPS corrections for plural proper nouns (“Securities”, “Brothers”, etc.);
  * Special cases for financial vocabulary, hyphenated compounds, and floor-trading terminology.

Perceptron (`st5393_Perceptron.py`)
----------------------------------
* Implements an averaged perceptron sequence model with history features. For each token we fire:
  * lexical cues (`word`, `lower`, `prefix/suffix`, `shape`, `isupper`, `isdigit`, hyphen flag);
  * contextual cues (previous two predicted tags, previous/next words, tag bigrams such as `prev_tag+word`).
* Training loops three epochs over `WSJ_02-21.pos`. After every update the weights are accumulated, and averaged at the end to reduce order-induced variance.
* Prediction is performed with a single left-to-right pass (using the previous two tags as features), so no Viterbi search is required. OOV tokens are handled implicitly by the lexical/character/context features—there is no reliance on explicit OOV dictionaries.
* This implementation is meant to benchmark the generative HMM approach, provide a platform for rapid feature experiments, and serve as a stepping stone toward structured perceptrons/CRFs. It reaches roughly 96.86% accuracy on `WSJ_24`.



Usage
-----
1. **HMM Decoder **
   ```bash
   python st5393_Viterbi.py
   ```
   * Trains on `WSJ_02-21.pos` and produces predictions for `WSJ_23.words` in `submission.pos`.
   * Intermediate development runs can be generated by pointing the decoder at `WSJ_24.words` and scoring with `python score.py WSJ_24.pos WSJ_24_sys.pos`.

2. **Perceptron Baseline(better) **
   ```bash
   python st5393_Perceptron.py
   ```
   * Implements a tag-history aware averaged perceptron with rich lexical/contextual features (word shape, suffix/prefix, previous tags, neighbouring words, etc.).
   * Runs three epochs over `WSJ_02-21.pos`, averages weights, reports `WSJ_24` accuracy (~96.86%), then writes `submission.pos` for `WSJ_23.words`.
   * Serves as a discriminative baseline; useful for cross-checking the HMM predictions or exploring feature engineering trade-offs, though slower to train than the HMM path.

